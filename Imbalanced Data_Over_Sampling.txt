# importing packages
import numpy as np
import pandas as pd
import scipy.stats as stats
import sklearn
import keras
import imblearn
import matplotlib.pyplot as plt
import seaborn as sns
plt.style.use('ggplot')

df = pd.read_csv("C:/Users/Sangamithra/Desktop/Data Sets/creditcardfraud.csv")
df.sample(5)

# taking a closer look at the class variable
sns.countplot('Class', data = df)
plt.title('No Fraud (0) vs. Fraud (1)')

#One common way to tackle the issue of imbalanced data is over-sampling. Over-sampling refers to various methods that aim to increase the number of instances from the underrepresented class in the data set.
#In our case, these techniques will increase the number of fraudulent transactions in our data (usually to 50:50). You might ask why one would even do that in the first place. Good question. If you do not balance the number of instances, most classification algorithms will heavily focus on the majority class. As a result, it might seem like your algorithm is achieving superb results when, in reality, it is simply always predicting the majority class.

#Random naive over-sampling
#The easiest way to do so is to randomly select observations from the minority class and add them to the data set until we achieve a balance between the majority and minority class. Since this is relatively straight-forward one would not necessarily have to use imblearn but could randomly select observations using NumPy for instance.
#In imblearn, one would do the following after splitting our data into x (all variables except for the class) and y (the class):

X = df.iloc[:,0:30]  #independent columns
y = df.iloc[:,-1]    #target column class

#imports 
from imblearn.over_sampling import RandomOverSampler

# random oversampling
ros = RandomOverSampler(random_state=0)
X_resampled, y_resampled = ros.fit_resample(X, y)

# using Counter to display results of naive oversampling
from collections import Counter
print(sorted(Counter(y_resampled).items()))

#Issue Above :
#One issue with random naive over-sampling is that it just duplicates already existing data. Therefore, while classification algorithms are exposed to a greater amount of observations from the minority class, they won’t learn more about how to tell fraudulent and non-fraudulent observations apart. The new data does not contain more information about the characteristics of fraudulent transactions than the old data.

##Synthetic Minority Over-Sampling Technique (SMOTE)
##A more advanced alternative to using random naive over-sampling is Synthetic Minority Over-Sampling Technique(SMOTE). While SMOTE still oversamples the minority class, it does not rely on reusing previously existing observations. Instead, SMOTE creates new (synthetic) observations based on the observations in your data. How does SMOTE do that? To illustrate my point, I’ve put together a fictional data set:

# importing SMOTE
from imblearn.over_sampling import SMOTE

# applying SMOTE to our data and checking the class counts
X_resampled, y_resampled = SMOTE().fit_resample(X, y)
print(sorted(Counter(y_resampled).items()))

#Adaptive Synthetic (ADASYN)
#ADASYN’s main advantage lies in its adaptive nature: by basing the number of synthetic observations on the ratio of majority to minority observations, ADASYN places a higher emphasis on more challenging regions of the data.

# importing ADASYN
from imblearn.over_sampling import ADASYN

# applying ADASYN
X_resampled, y_resampled = ADASYN().fit_resample(X, y)
print(sorted(Counter(y_resampled).items()))

#BorderlineSMOTE: Instead of oversampling between all minority observations, BorderlineSMOTE aims to increase the number of minority observations that border majority observations. The goal here is to allow the classifier to be able to distinguish between these borderline observations more clearly.

# BorderlineSMOTE
from imblearn.over_sampling import BorderlineSMOTE

X_resampled, y_resampled = BorderlineSMOTE().fit_resample(X, y)
print(sorted(Counter(y_resampled).items()))

https://towardsdatascience.com/a-deep-dive-into-imbalanced-data-over-sampling-f1167ed74b5
